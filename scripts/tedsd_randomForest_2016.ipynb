{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from numpy import loadtxt\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing ... df1\n",
      "Finished processing ... df2\n",
      "Finished processing ... df3\n",
      "Finished processing ... frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonahwu/miniconda3/envs/pysal2_1_release/lib/python3.6/site-packages/ipykernel_launcher.py:9: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the very original dataset size: (1458045, 248)\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv(\"../data/one-hotted-tedsd/updated_2016_3_v2.csv\")\n",
    "print(\"Finished processing ... df1\");\n",
    "df2 = pd.read_csv(\"../data/one-hotted-tedsd/updated_2016_2_v2.csv\")\n",
    "print(\"Finished processing ... df2\");\n",
    "df3 = pd.read_csv(\"../data/one-hotted-tedsd/update_2016_1_v3.csv\")\n",
    "print(\"Finished processing ... df3\");\n",
    "frames = [df1, df2, df3]\n",
    "print(\"Finished processing ... frames\");\n",
    "original_df = pd.concat(frames)\n",
    "print(\"This is the very original dataset size: \" + str(original_df.shape))\n",
    "\n",
    "df_copy = original_df.copy(deep=True).sample(frac=1)\n",
    "dataset = df_copy.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ALCFLG': 0, 'AMPHFLG': 1, 'ARRESTS': 2, 'BARBFLG': 3, 'BENZFLG': 4, 'COKEFLG': 5, 'DSMCRIT': 6, 'HALLFLG': 7, 'HERFLG': 8, 'IDU': 9, 'INHFLG': 10, 'MARFLG': 11, 'METHFLG': 12, 'MTHAMFLG': 13, 'NOPRIOR': 14, 'OPSYNFLG': 15, 'OTCFLG': 16, 'OTHERFLG': 17, 'PCPFLG': 18, 'PSYPROB': 19, 'SEDHPFLG': 20, 'STIMFLG': 21, 'TRNQFLG': 22, 'age_approx': 23, 'alcdrug_alc': 24, 'alcdrug_both': 25, 'alcdrug_drug': 26, 'alcdrug_none': 27, 'daywait_approx': 28, 'division_enc': 29, 'division_esc': 30, 'division_ma': 31, 'division_mt': 32, 'division_ne': 33, 'division_pc': 34, 'division_sa': 35, 'division_territory': 36, 'division_wnc': 37, 'division_wsc': 38, 'educ_approx': 39, 'employ_full': 40, 'employ_nlf': 41, 'employ_part': 42, 'employ_unemployed': 43, 'employ_unknown': 44, 'ethnic_cuban': 45, 'ethnic_latino': 46, 'ethnic_mexican': 47, 'ethnic_none': 48, 'ethnic_puerto': 49, 'ethnic_unknown': 50, 'firstuse1_approx': 51, 'firstuse2_approx': 52, 'freq1_daily': 53, 'freq1_none': 54, 'freq1_some': 55, 'freq1_unknown': 56, 'freq2_daily': 57, 'freq2_none': 58, 'freq2_some': 59, 'freq2_unknown': 60, 'freq3_daily': 61, 'freq3_none': 62, 'freq3_some': 63, 'freq3_unknown': 64, 'freq_atnd_self_help_approx': 65, 'gender_female': 66, 'gender_male': 67, 'gender_unknown': 68, 'livarag_dependent': 69, 'livarag_homeless': 70, 'livarag_independent': 71, 'livarag_unknown': 72, 'marstat_divorced': 73, 'marstat_married': 74, 'marstat_separated': 75, 'marstat_single': 76, 'marstat_unknown': 77, 'methuse': 78, 'methuse_unknown': 79, 'preg_unknown': 80, 'pregnant': 81, 'priminc_none': 82, 'priminc_other': 83, 'priminc_public': 84, 'priminc_retirement': 85, 'priminc_unknown': 86, 'priminc_wages': 87, 'psource_alc_drug': 88, 'psource_community': 89, 'psource_court': 90, 'psource_employer': 91, 'psource_health': 92, 'psource_individual': 93, 'psource_school': 94, 'psource_unknown': 95, 'race_alaska': 96, 'race_asian': 97, 'race_black': 98, 'race_multiple': 99, 'race_native': 100, 'race_single': 101, 'race_unknown': 102, 'race_white': 103, 'reason': 104, 'region_midwest': 105, 'region_ne': 106, 'region_south': 107, 'region_territory': 108, 'region_west': 109, 'route1_inhalation': 110, 'route1_injection': 111, 'route1_oral': 112, 'route1_other': 113, 'route1_smoke': 114, 'route1_unknown': 115, 'route2_inhalation': 116, 'route2_injection': 117, 'route2_oral': 118, 'route2_other': 119, 'route2_smoke': 120, 'route2_unknown': 121, 'route3_inhalation': 122, 'route3_injection': 123, 'route3_oral': 124, 'route3_other': 125, 'route3_smoke': 126, 'route3_unknown': 127, 'service_amb_dt': 128, 'service_amb_in': 129, 'service_amb_nin': 130, 'service_dt_24_h': 131, 'service_dt_24_r': 132, 'service_re_h': 133, 'service_re_long': 134, 'service_re_short': 135, 'stfips_0in': 136, 'stfips_ak': 137, 'stfips_al': 138, 'stfips_ar': 139, 'stfips_az': 140, 'stfips_ca': 141, 'stfips_co': 142, 'stfips_ct': 143, 'stfips_dc': 144, 'stfips_de': 145, 'stfips_fl': 146, 'stfips_hi': 147, 'stfips_ia': 148, 'stfips_id': 149, 'stfips_il': 150, 'stfips_in': 151, 'stfips_ks': 152, 'stfips_ky': 153, 'stfips_la': 154, 'stfips_ma': 155, 'stfips_md': 156, 'stfips_me': 157, 'stfips_mi': 158, 'stfips_mn': 159, 'stfips_mo': 160, 'stfips_ms': 161, 'stfips_mt': 162, 'stfips_nc': 163, 'stfips_nd': 164, 'stfips_ne': 165, 'stfips_nh': 166, 'stfips_nj': 167, 'stfips_nm': 168, 'stfips_nv': 169, 'stfips_ny': 170, 'stfips_oh': 171, 'stfips_ok': 172, 'stfips_pa': 173, 'stfips_pc': 174, 'stfips_ri': 175, 'stfips_sc': 176, 'stfips_sd': 177, 'stfips_tn': 178, 'stfips_tx': 179, 'stfips_ut': 180, 'stfips_va': 181, 'stfips_vt': 182, 'stfips_wa': 183, 'stfips_wi': 184, 'stfips_wy': 185, 'sub1_alcohol': 186, 'sub1_amphetamines': 187, 'sub1_barbiturates': 188, 'sub1_benzos': 189, 'sub1_cocaine': 190, 'sub1_hallucinogens': 191, 'sub1_heroin': 192, 'sub1_inhalants': 193, 'sub1_meth': 194, 'sub1_methadone': 195, 'sub1_none': 196, 'sub1_opiates': 197, 'sub1_otc': 198, 'sub1_other': 199, 'sub1_pcp': 200, 'sub1_sedatives': 201, 'sub1_stimulants': 202, 'sub1_tranqs': 203, 'sub1_unknown': 204, 'sub1_weed': 205, 'sub2_alcohol': 206, 'sub2_amphetamines': 207, 'sub2_barbiturates': 208, 'sub2_benzos': 209, 'sub2_cocaine': 210, 'sub2_hallucinogens': 211, 'sub2_heroin': 212, 'sub2_inhalants': 213, 'sub2_meth': 214, 'sub2_methadone': 215, 'sub2_none': 216, 'sub2_opiates': 217, 'sub2_otc': 218, 'sub2_other': 219, 'sub2_pcp': 220, 'sub2_sedatives': 221, 'sub2_stimulants': 222, 'sub2_tranqs': 223, 'sub2_unknown': 224, 'sub2_weed': 225, 'sub3_alcohol': 226, 'sub3_amphetamines': 227, 'sub3_barbiturates': 228, 'sub3_benzos': 229, 'sub3_cocaine': 230, 'sub3_hallucinogens': 231, 'sub3_heroin': 232, 'sub3_inhalants': 233, 'sub3_meth': 234, 'sub3_methadone': 235, 'sub3_none': 236, 'sub3_opiates': 237, 'sub3_otc': 238, 'sub3_other': 239, 'sub3_pcp': 240, 'sub3_sedatives': 241, 'sub3_stimulants': 242, 'sub3_tranqs': 243, 'sub3_unknown': 244, 'sub3_weed': 245, 'vet_unknown': 246, 'veteran': 247}\n",
      "['service_dt_24_r', 'service_amb_nin', 'service_amb_in', 'service_re_short', 'methuse', 'psource_court', 'stfips_co', 'region_midwest', 'region_west', 'stfips_ky', 'division_mt', 'stfips_fl', 'employ_full', 'stfips_mo', 'division_sa', 'freq1_none', 'division_esc', 'division_enc', 'stfips_nj', 'psource_health', 'sub1_alcohol', 'livarag_unknown', 'stfips_md', 'ARRESTS', 'livarag_homeless', 'ALCFLG', 'race_white', 'priminc_unknown', 'psource_individual', 'region_ne', 'vet_unknown', 'marstat_single', 'sub2_none', 'priminc_wages', 'stfips_mi', 'service_re_long', 'livarag_dependent', 'sub1_weed', 'stfips_ny', 'gender_female', 'stfips_la', 'division_wnc', 'stfips_ne', 'priminc_public', 'race_black', 'OPSYNFLG', 'stfips_il', 'route1_inhalation', 'stfips_sc', 'route1_smoke', 'sub1_opiates', 'stfips_az', 'sub1_heroin', 'BENZFLG', 'ethnic_mexican', 'freq2_daily', 'route1_injection', 'sub1_unknown', 'route1_oral', 'stfips_ct', 'freq2_some', 'division_ma', 'stfips_tn', 'stfips_ks', 'division_ne', 'service_dt_24_h', 'sub1_none', 'marstat_married', 'sub3_unknown', 'sub2_weed', 'IDU', 'priminc_retirement', 'HERFLG', 'methuse_unknown', 'freq1_daily', 'stfips_ca', 'MARFLG', 'race_native', 'sub1_meth', 'race_unknown', 'stfips_sd', 'sub3_none', 'sub2_other', 'priminc_none', 'freq3_daily', 'sub2_benzos', 'OTHERFLG', 'stfips_mn', 'route2_injection', 'educ_approx', 'stfips_ar', 'stfips_ok', 'employ_nlf', 'stfips_vt', 'stfips_ma', 'ethnic_none', 'livarag_independent', 'employ_unemployed', 'gender_male', 'MTHAMFLG', 'stfips_nc', 'veteran', 'priminc_other', 'marstat_separated', 'ethnic_cuban', 'stfips_wa', 'psource_alc_drug', 'preg_unknown', 'sub1_cocaine', 'service_re_h', 'stfips_tx', 'stfips_nv', 'stfips_dc', 'age_approx', 'PSYPROB', 'employ_unknown', 'stfips_hi', 'freq2_none', 'route2_inhalation', 'psource_unknown', 'sub2_heroin', 'route2_smoke', 'service_amb_dt', 'route2_oral', 'sub3_benzos', 'firstuse1_approx', 'stfips_wi', 'psource_community', 'psource_employer', 'marstat_unknown', 'psource_school', 'stfips_ms', 'race_multiple', 'sub1_benzos', 'stfips_ia', 'route3_smoke', 'division_pc', 'NOPRIOR', 'marstat_divorced', 'ethnic_latino', 'stfips_oh', 'sub3_cocaine', 'route3_oral']\n",
      "Shape of dataset following feature deletion:  (1458045, 143)\n",
      "Label Dimensions: (1458045, 1)\n"
     ]
    }
   ],
   "source": [
    "#Extract Features\n",
    "dataFields = {}\n",
    "for x in range(len(df_copy.columns)):\n",
    "\tdataFields.update({df_copy.columns[x]: x})\n",
    "print(dataFields)\n",
    "indx = dataFields[\"reason\"]\n",
    "Y = dataset[:,[indx]]\n",
    "Y = np.select([(Y == 1)], [1] , default = 0) #Set to binary classification\n",
    "\n",
    "featureWeights = pd.read_csv(\"../data/rankedFeatures.csv\")\n",
    "fields = list(featureWeights[\"field\"])\n",
    "desiredChars = [fields[x] for x in range(143)]\n",
    "print(desiredChars)\n",
    "indxsToDelete = []\n",
    "for key, value in dataFields.items():\n",
    "    if key not in desiredChars:\n",
    "        indxsToDelete.append(value)\n",
    "\n",
    "X = np.delete(dataset, indxsToDelete, 1)\n",
    "print(\"Shape of dataset following feature deletion: \", X.shape)\n",
    "print(\"Label Dimensions:\", Y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = .05\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size)\n",
    "eval_set=[(X_train, y_train.ravel()), (X_test, y_test.ravel())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=6, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=150,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=1, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 150 out of 150 | elapsed: 15.9min finished\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(max_depth=6, verbose=1, n_estimators=150)\n",
    "model.fit(X_train, y_train.ravel())\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 150 out of 150 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 65.26%\n",
      "Precision: 0.789805\n",
      "Recall: 0.213115\n",
      "F1 score: 0.335659\n",
      "Train scores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 150 out of 150 | elapsed:   14.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 65.17%\n",
      "Precision: 0.785985\n",
      "Recall: 0.209670\n",
      "F1 score: 0.331034\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy*100.0))\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print('F1 score: %f' % f1)\n",
    "\n",
    "print(\"Train scores...\")\n",
    "y_pred = model.predict(X_train)\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy*100.0))\n",
    "precision = precision_score(y_train, y_pred)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(y_train, y_pred)\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(y_train, y_pred)\n",
    "print('F1 score: %f' % f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
